# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Overview

DATect is a scientific machine learning system for forecasting domoic acid (DA) concentrations along the Pacific Coast using satellite oceanographic data, climate indices, and historical measurements. This is a research-grade forecasting system designed for peer review and operational deployment with strict temporal safeguards to prevent data leakage.

## Core Architecture

### Data Processing Pipeline
- **dataset-creation.py**: Complete data processing pipeline that downloads and processes satellite data, environmental indices, and toxin measurements into a unified dataset (30-60 min runtime)
- **data/**: Organized storage with raw/, intermediate/, and processed/ directories for clean data management
- **config.py**: Central configuration file containing all settings, data sources, and model parameters

### Forecasting System
- **modular-forecast.py**: Main forecasting application with multiple operation modes
- **forecasting/core/**: Core modules for forecasting logic
  - `forecast_engine.py`: Main forecasting logic with strict temporal integrity protection
  - `data_processor.py`: Data preprocessing and transformation
  - `model_factory.py`: ML model creation (XGBoost primary, Ridge/Logistic fallback)
  - `logging_config.py`: Centralized logging configuration
  - `exception_handling.py`: Error handling utilities

### Dashboard System  
- **forecasting/dashboard/**: Interactive web dashboards
  - `realtime.py`: Real-time forecasting interface (port 8066)
  - `retrospective.py`: Historical analysis interface (port 8071)

### Scientific Validation Framework
- **analysis/scientific-validation/**: Comprehensive test suite for peer review readiness
  - `test_temporal_integrity.py`: Critical tests preventing data leakage (7 unit tests)
  - `scientific_validation.py`: Statistical validation and ACF/PACF analysis
  - `run_scientific_validation.py`: Complete validation suite runner

## Essential Commands

### Data Processing
```bash
# Process complete dataset (30-60 min runtime, downloads ~2GB satellite data)
python dataset-creation.py

# Check if processed data exists
ls -la data/processed/final_output.parquet
```

### Forecasting System
```bash
# Run main forecasting system (uses config.py settings)
python modular-forecast.py

# Configuration options in config.py:
# FORECAST_MODE: "retrospective" or "realtime" 
# FORECAST_MODEL: "xgboost" or "ridge"
# FORECAST_TASK: "regression" or "classification"
```

### Scientific Validation & Testing
```bash
# Run complete pipeline test (integration test, <60s)
python tools/testing/test_complete_pipeline.py

# Run temporal integrity tests (CRITICAL - prevents data leakage)
python analysis/scientific-validation/test_temporal_integrity.py

# Run full scientific validation suite
python analysis/scientific-validation/run_scientific_validation.py

# Run performance analysis
python analysis/scientific-validation/performance_profiler.py
```

## Key Configuration Settings

### Model Configuration (config.py)
- **FORECAST_MODE**: Controls operation type
  - `"retrospective"`: Historical validation with random anchor points  
  - `"realtime"`: Interactive dashboard for specific predictions
- **FORECAST_MODEL**: ML algorithm selection
  - `"xgboost"`: Primary model with superior performance
  - `"ridge"`: Linear fallback (Ridge/Logistic based on task)
- **LAG_FEATURES**: Time series lags `[1, 3]` (optimized via ACF/PACF analysis)

### Temporal Safeguards (CRITICAL)
- **TEMPORAL_BUFFER_DAYS**: 1 day minimum between training and prediction
- **SATELLITE_BUFFER_DAYS**: 7 days for satellite data temporal cutoff  
- **CLIMATE_BUFFER_MONTHS**: 2 months for climate index reporting delays

### Data Sources
- 10 Pacific Coast monitoring sites from Washington to Oregon
- MODIS satellite data (chlorophyll, SST, PAR, fluorescence, K490)
- Climate indices (PDO, ONI, BEUTI) from NOAA ERDDAP
- USGS streamflow data for Columbia River

## Scientific Requirements

### Temporal Integrity (NON-NEGOTIABLE)
All forecasts must pass temporal integrity validation to prevent data leakage:
- Lag features must be NaN when accessing future data
- Training/test splits must maintain strict chronological order
- Preprocessing must fit only on training data
- All 7 temporal integrity unit tests must pass

### Model Performance Standards
- XGBoost regression: RÂ² > 0.85 for validation
- Processing speed: >85,000 samples/second
- Memory usage: <250MB peak
- Temporal coverage: 2003-2023 (21 years)

### Testing Requirements
Before any deployment or modification:
1. Run `test_complete_pipeline.py` (all 5 components must pass)
2. Run `test_temporal_integrity.py` (all 7 tests must pass)
3. Validate scientific analysis with `run_scientific_validation.py`

## Development Workflows

### Adding New Features
1. Check temporal integrity implications
2. Update configuration in `config.py` if needed
3. Run complete test suite before committing
4. Validate performance impact with profiler

### Modifying Data Processing
1. **ALWAYS** run temporal integrity tests after changes
2. Validate with scientific validation suite
3. Check that output format matches expected schema
4. Test with both retrospective and realtime modes

### Dashboard Development  
1. Test both `realtime.py` (port 8066) and `retrospective.py` (port 8071)
2. Ensure forecasting engine integration works
3. Validate with different FORECAST_MODE settings

## Important Notes

### Data Dependencies
- Processed dataset: `data/processed/final_output.parquet` (10,950 samples)
- Satellite cache: `data/intermediate/satellite_data_intermediate.parquet`
- Raw data: DA measurements in `data/raw/da-input/`, PN data in `data/raw/pn-input/`

### Performance Characteristics
- Data processing: 30-60 minutes (downloads ~2GB satellite data)
- Forecasting: <10 seconds for complete analysis
- Memory footprint: <250MB
- Test suite: <60 seconds for complete validation

### Scientific Validation Status
- **100% test success rate** across all components
- **Zero data leakage** confirmed through comprehensive testing
- **Peer-review ready** with statistical validation of all methods
- **Production validated** with excellent performance benchmarks

The system is designed for research applications requiring strict temporal integrity and is ready for peer review and operational deployment.