# ğŸ† Spike Detection Model Championship Report

**Generated:** 2025-09-01 00:22:56  
**Spike Threshold:** 20.0 ppm  
**Temporal Window:** 7 days  

## ğŸ¯ Championship Overview

This report presents the results of a comprehensive comparison between multiple machine learning models
and naive baselines for domoic acid spike timing prediction.

### ğŸ”¬ Models Tested

**ML Models (3):** xgboost, ensemble, linear  
**Baselines (2):** naive_7d_lag, persistence  

## ğŸ“Š Performance Summary

| Model | Type | F1 Score | Precision | Recall | Spike MAE | Overall RÂ² |
|-------|------|----------|-----------|--------|-----------|------------|
| Naive 7D Lag | Baseline | 0.842 | 0.842 | 0.842 | 11.46 | 0.776 |
| Persistence | Baseline | 0.842 | 0.842 | 0.842 | 11.46 | 0.776 |
| Ensemble | ML Model | 0.571 | 0.909 | 0.417 | 31.88 | 0.106 |
| Xgboost | ML Model | 0.438 | 0.583 | 0.350 | 24.15 | 0.435 |
| Linear | ML Model | 0.000 | 0.000 | 0.000 | 46.20 | -0.083 |

## ğŸ” Key Findings

### ğŸ¥‡ Best Overall Performer: Naive 7D Lag
- **F1 Score:** 0.842
- **Precision:** 0.842
- **Recall:** 0.842

### âš¡ ML vs Baseline Comparison
- **Best ML Model:** Ensemble (F1: 0.571)
- **Best Baseline:** Naive 7D Lag (F1: 0.842)
- **Improvement:** -0.271

âŒ **Conclusion:** ML models do not significantly outperform baselines.

## ğŸ¯ Recommendations

Based on the championship results:

1. **Production Model:** Consider the best-performing model for deployment
2. **Baseline Validation:** Always validate against naive baselines
3. **Spike Focus:** Continue emphasizing spike timing over overall accuracy
4. **Further Development:** Investigate hybrid approaches combining top models

---
*Report generated by DATect Spike Model Championship*
